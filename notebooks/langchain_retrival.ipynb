{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-01-24T18:22:23.452512Z",
     "start_time": "2024-01-24T18:22:22.968628Z"
    }
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "import openai\n",
    "\n",
    "from rag_diary.config import Config\n",
    "\n",
    "current_folder = Path(globals()['_dh'][0])\n",
    "load_dotenv(Path(current_folder).parent / \".env\")\n",
    "\n",
    "config = Config()\n",
    "openai.api_key = config.OPENAI_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from rag_diary.vector_store_chromadb import VectorStoreChromadb, get_chromadb_collection\n",
    "from langchain_openai.embeddings import OpenAIEmbeddings\n",
    "import chromadb\n",
    "from chromadb.utils.embedding_functions import OpenAIEmbeddingFunction\n",
    "\n",
    "\n",
    "db_path = Path(current_folder).joinpath(\"../private.db.chroma\") \n",
    "embedding_function = OpenAIEmbeddings(api_key=config.OPENAI_API_KEY, model=config.OPENAI_MODEL_NAME)\n",
    "\n",
    "collection_name = \"langchain_retrival\"\n",
    "embeddings = OpenAIEmbeddings()\n",
    "client = chromadb.PersistentClient(path=str(db_path.absolute()))\n",
    "collection = get_chromadb_collection(\n",
    "    client,\n",
    "    collection_name=config.DEFAULT_DB_NAME,\n",
    "    embedding_function=embedding_function\n",
    ")\n",
    "vector_store = VectorStoreChromadb(client=client, collection=collection)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-24T18:22:24.534654Z",
     "start_time": "2024-01-24T18:22:23.455916Z"
    }
   },
   "id": "847b184c6ef8725b",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "docs = [\n",
    "    \"Basquetball is a great sport.\",\n",
    "    \"Fly me to the moon is one of my favourite songs.\",\n",
    "    \"The Celtics are my favourite team.\",\n",
    "    \"This is a document about the Boston Celtics\",\n",
    "    \"I simply love going to the movies\",\n",
    "    \"The Boston Celtics won the game by 20 points\",\n",
    "    \"This is just a random text.\",\n",
    "    \"Elden Ring is one of the best games in the last 15 years.\",\n",
    "    \"L. Kornet is one of the best Celtics players.\",\n",
    "    \"Larry Bird was an iconic NBA player.\",\n",
    "]\n",
    "vector_store.add_multiple(docs, [{\"id\":idx} for idx in range(len(docs))])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-24T18:22:25.422712Z",
     "start_time": "2024-01-24T18:22:24.536616Z"
    }
   },
   "id": "610b940ddb26c2b3",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "['Elden Ring is one of the best games in the last 15 years.',\n 'Elden Ring is one of the best games in the last 15 years.',\n 'Elden Ring is one of the best games in the last 15 years.',\n 'Basquetball is a great sport.',\n 'Basquetball is a great sport.',\n 'Basquetball is a great sport.',\n 'The Celtics are my favourite team.',\n 'The Celtics are my favourite team.',\n 'The Celtics are my favourite team.',\n 'The Boston Celtics won the game by 20 points']"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"what is the best game\"\n",
    "data = vector_store.query_by_str(query)\n",
    "docs = [d[\"document\"] for d in data]\n",
    "\n",
    "docs"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-24T18:22:25.491673Z",
     "start_time": "2024-01-24T18:22:25.425798Z"
    }
   },
   "id": "19ae4e4ed38ee097",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(page_content='Elden Ring is one of the best games in the last 15 years.'), Document(page_content='Basquetball is a great sport.'), Document(page_content='The Celtics are my favourite team.'), Document(page_content='I simply love going to the movies')]\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.vectorstores import Chroma\n",
    "\n",
    "texts = [\n",
    "    \"Basquetball is a great sport.\",\n",
    "    \"Fly me to the moon is one of my favourite songs.\",\n",
    "    \"The Celtics are my favourite team.\",\n",
    "    \"This is a document about the Boston Celtics\",\n",
    "    \"I simply love going to the movies\",\n",
    "    \"The Boston Celtics won the game by 20 points\",\n",
    "    \"This is just a random text.\",\n",
    "    \"Elden Ring is one of the best games in the last 15 years.\",\n",
    "    \"L. Kornet is one of the best Celtics players.\",\n",
    "    \"Larry Bird was an iconic NBA player.\",\n",
    "]\n",
    "\n",
    "db = Chroma(\n",
    "    collection_name=collection_name,\n",
    "    embedding_function=embedding_function,\n",
    "    persist_directory=str(str(db_path.absolute()))\n",
    ")\n",
    "\n",
    "db.add_texts(texts=texts)\n",
    "   \n",
    "retriever = db.as_retriever()\n",
    "query = \"What is the best game\"\n",
    "\n",
    "docs = retriever.get_relevant_documents(query)\n",
    "print(docs)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-24T18:22:26.606197Z",
     "start_time": "2024-01-24T18:22:25.486045Z"
    }
   },
   "id": "e4b454cabdc2ab15",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.documents.base.Document'>\n",
      "<class 'langchain_core.documents.base.Document'>\n",
      "<class 'langchain_core.documents.base.Document'>\n",
      "<class 'langchain_core.documents.base.Document'>\n"
     ]
    },
    {
     "data": {
      "text/plain": "[Document(page_content='Basquetball is a great sport.'),\n Document(page_content='I simply love going to the movies'),\n Document(page_content='The Celtics are my favourite team.'),\n Document(page_content='Elden Ring is one of the best games in the last 15 years.')]"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.document_transformers import LongContextReorder\n",
    "\n",
    "# Reorder the documents:\n",
    "# Less relevant document will be at the middle of the list and more\n",
    "# relevant elements at beginning / end.\n",
    "reordering = LongContextReorder()\n",
    "reordered_docs = reordering.transform_documents(docs)\n",
    "\n",
    "[print(type(doc)) for doc in reordered_docs]\n",
    "# Confirm that the 4 relevant documents are at beginning and end.\n",
    "reordered_docs"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-24T18:22:28.449313Z",
     "start_time": "2024-01-24T18:22:28.299874Z"
    }
   },
   "id": "fd6d07c494fabad6",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from langchain.chains import LLMChain, StuffDocumentsChain\n",
    "from langchain_openai import OpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "template = \"\"\"Given this text extracts:\n",
    "# -----\n",
    "# {context}\n",
    "# -----\n",
    "# Please answer the following question:\n",
    "# {query}\"\"\"\n",
    "document_variable_name = \"context\"\n",
    "prompt = PromptTemplate(\n",
    "    template=template,\n",
    "    input_variables=[\"query\", document_variable_name ],\n",
    ")\n",
    "\n",
    "  "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-24T18:22:55.039200Z",
     "start_time": "2024-01-24T18:22:55.036060Z"
    }
   },
   "id": "62cba43e751de8bb",
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "{'query': 'what is the best game',\n 'input_documents': [Document(page_content='Basquetball is a great sport.'),\n  Document(page_content='I simply love going to the movies'),\n  Document(page_content='The Celtics are my favourite team.'),\n  Document(page_content='Elden Ring is one of the best games in the last 15 years.')],\n 'output_text': ' in the last 15 years?\\n\\nElden Ring is one of the best games in the last 15 years.'}"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_prompt = PromptTemplate(\n",
    "    input_variables=[\"page_content\"],\n",
    "    template=\"{page_content}\"\n",
    ")\n",
    "\n",
    "llm = OpenAI()\n",
    "# The prompt here should take as an input variable the\n",
    "# `document_variable_name`\n",
    "\n",
    "llm_chain = LLMChain(llm=llm, prompt=prompt)\n",
    "chain = StuffDocumentsChain(\n",
    "    llm_chain=llm_chain,\n",
    "    document_prompt=document_prompt,\n",
    "    document_variable_name=\"context\"\n",
    ")\n",
    "\n",
    "chain.invoke( query=query, input={\"query\": \"what is the best game\", \"input_documents\": reordered_docs})"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-24T18:22:57.732338Z",
     "start_time": "2024-01-24T18:22:55.681176Z"
    }
   },
   "id": "26ad1f83df08ef08",
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Collection langchain_retrival does not exist.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[81], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mclient_chromadb\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdelete_collection\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcollection_name\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/code/rag-diary/venv/lib/python3.10/site-packages/chromadb/api/client.py:264\u001B[0m, in \u001B[0;36mClient.delete_collection\u001B[0;34m(self, name)\u001B[0m\n\u001B[1;32m    259\u001B[0m \u001B[38;5;129m@override\u001B[39m\n\u001B[1;32m    260\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdelete_collection\u001B[39m(\n\u001B[1;32m    261\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m    262\u001B[0m     name: \u001B[38;5;28mstr\u001B[39m,\n\u001B[1;32m    263\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m--> 264\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_server\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdelete_collection\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    265\u001B[0m \u001B[43m        \u001B[49m\u001B[43mname\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    266\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtenant\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtenant\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    267\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdatabase\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdatabase\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    268\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/code/rag-diary/venv/lib/python3.10/site-packages/chromadb/telemetry/opentelemetry/__init__.py:127\u001B[0m, in \u001B[0;36mtrace_method.<locals>.decorator.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    125\u001B[0m \u001B[38;5;28;01mglobal\u001B[39;00m tracer, granularity\n\u001B[1;32m    126\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m trace_granularity \u001B[38;5;241m<\u001B[39m granularity:\n\u001B[0;32m--> 127\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mf\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    128\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m tracer:\n\u001B[1;32m    129\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m f(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[0;32m~/code/rag-diary/venv/lib/python3.10/site-packages/chromadb/api/segment.py:346\u001B[0m, in \u001B[0;36mSegmentAPI.delete_collection\u001B[0;34m(self, name, tenant, database)\u001B[0m\n\u001B[1;32m    344\u001B[0m         \u001B[38;5;28;01mdel\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_collection_cache[existing[\u001B[38;5;241m0\u001B[39m][\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mid\u001B[39m\u001B[38;5;124m\"\u001B[39m]]\n\u001B[1;32m    345\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 346\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCollection \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mname\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m does not exist.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[0;31mValueError\u001B[0m: Collection langchain_retrival does not exist."
     ]
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-22T23:20:59.596318Z",
     "start_time": "2024-01-22T23:20:59.538445Z"
    }
   },
   "id": "4d6800bd4ea749fc",
   "execution_count": 81
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "11e658b97d1f9b6d"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
